{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9300f312",
      "metadata": {},
      "source": [
        "### Objection Detection and Computer Vision\n",
        "\n",
        "Through the rest of this notebook, we'll be exploring different steps in creating an object detection algorithm. By the end, you should know how to use a pre-trained YOLO model to:\n",
        "\n",
        "- Identify objects\n",
        "- Create bounding boxes\n",
        "- Count total detected\n",
        "- Label individual items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8602334",
      "metadata": {},
      "source": [
        "#### 1. Understanding Object Detection\n",
        "\n",
        "Objective: Learn the basics of object detection and understand how a model can detect objects in an image.\n",
        "\n",
        "Steps:\n",
        "1. Understand what object detection is.\n",
        "2. Learn about bounding boxes.\n",
        "3. Identify objects in a given image.\n",
        "\n",
        "Look at the provided image and list all the objects you see. Draw bounding boxes around each object (you can do this on paper)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68788781",
      "metadata": {},
      "source": [
        "#### 2. Implementing Object Detection\n",
        "\n",
        "Now that we have a solid conceptual understanding, we're going to work to implement each of the things you did on paper with code.\n",
        "\n",
        "##### 2.1 Installing Necessary Libraries\n",
        "First, we need to install some Python libraries that we'll use in this notebook. Comment the first line of the next block out if you want to see the output of the pip install.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e576783",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture \n",
        "%pip install ultralytics supervision opencv-python;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "047f4200",
      "metadata": {},
      "source": [
        "##### 2.2 Import Necessary Libraries and Helpers\n",
        "\n",
        "Let's import the necessary libraries and helpers. The display function will help you display the images you create using the results from your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "404e37d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd84019",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper Functions DO NOT CHANGE\n",
        "def display(image, title):\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17cd1566",
      "metadata": {},
      "source": [
        "##### 2.3 Loading a Smaller Pre-trained YOLOv8 Model\n",
        "\n",
        "We're going to load a smaller version of the YOLOv8 model (yolov8s.pt) to avoid memory issues. To do this we need to initialize the model and the fuse its layers. Check out the YOLO documentation to see which functions to use.\n",
        "\n",
        "- [General](https://docs.ultralytics.com/models/yolov8/)\n",
        "- [Fuse](https://docs.ultralytics.com/reference/engine/model/)\n",
        "\n",
        "Hint: Check out the usage examples and method table. Don't overthink this one. It should be just a few lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0f7c21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a smaller version of the model\n",
        "\n",
        "# We add the print statement to confirm that we reach the end of the code block.\n",
        "print('Model loaded successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f62e9bd",
      "metadata": {},
      "source": [
        "##### 2.4 Running Object Detection on the Image\n",
        "\n",
        "Let's use the model to detect objects in the resized image. Set a variable called results (empty string for now) which contains the output of running the model on the image.\n",
        "\n",
        "- [General](https://docs.ultralytics.com/models/yolov8/)\n",
        "\n",
        "Hint: Check out the usage examples. You should only need 1 line of code for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97d67a41",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the image from file\n",
        "image = cv2.imread('test.jpg')\n",
        "\n",
        "# Perform object detection using YOLOv8 model\n",
        "results = \"\"\n",
        "\n",
        "display(image, 'Detected Objects')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcfaead9",
      "metadata": {},
      "source": [
        "##### 2.5 Creating Bounding Boxes\n",
        "\n",
        "Now that we have the detection results from the model, we need to annotate the original image with bounding boxes for each detected object. You will write a function that uses for loops to iterate over the detection results and draw the bounding boxes on the image. This documentation will breakdown the different categories of the results.\n",
        "\n",
        "- [Results](https://docs.ultralytics.com/reference/engine/results/)\n",
        "\n",
        "Hint: Try printing out results to figure out how to access the bounding box coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d616156",
      "metadata": {},
      "outputs": [],
      "source": [
        "annotated_image = image.copy()\n",
        "\n",
        "def add_bounding_boxes(image):\n",
        "    pass\n",
        "\n",
        "add_bounding_boxes(annotated_image)\n",
        "\n",
        "# Display the annotated image with bounding boxes, labels, confidences, and object count\n",
        "display(annotated_image, 'Detected Objects with Bounding Boxes')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a8cebb",
      "metadata": {},
      "source": [
        "##### 2.6 Counting Objects Detected\n",
        "\n",
        "Build off your bounding boxes function to also figure out the total object count. There are a few ways to do this but at the end of the day all you need is to return a number to add to the label of \"Total Object Detected\".\n",
        "\n",
        "- [Results](https://docs.ultralytics.com/reference/engine/results/)\n",
        "\n",
        "Hint: This doesn't have to do directly with the results object but looking at it again and going through the logic of your bounding boxes function should help."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8baa1c3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "counted_image = image.copy()\n",
        "\n",
        "def add_bounding_boxes_and_count(image):\n",
        "    return object_count\n",
        "\n",
        "object_count = add_bounding_boxes_and_count(counted_image)\n",
        "\n",
        "# Add the object count text to the image\n",
        "text = f'Total Objects Detected: {object_count}'\n",
        "cv2.putText(counted_image, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "# Display the annotated image with bounding boxes and object count\n",
        "display(counted_image, 'Detected Objects with Bounding Boxes and Count')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7779a42a",
      "metadata": {},
      "source": [
        "##### 2.7 Adding Labels\n",
        "\n",
        "Now that you have the bounding boxes and count, let's add labels. We're still going to add to the same function. You need to identify what class each object is and the associated model name.\n",
        "\n",
        "- [Names](https://docs.ultralytics.com/reference/engine/model/#ultralytics.engine.model.Model.names)\n",
        "\n",
        "Hint: Go back to the results object and see if you can figure out how to extract the names. Below is the code you'll need to render the labels onto the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b7f6047",
      "metadata": {},
      "outputs": [],
      "source": [
        "# cv2.putText(labeled_image, label, (int(xmin), int(ymin) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86eb23fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "labeled_image = image.copy()\n",
        "\n",
        "def add_bounding_boxes_count_and_labels(image):\n",
        "    return object_count\n",
        "\n",
        "object_count = add_bounding_boxes_count_and_labels(labeled_image)\n",
        "\n",
        "# Add the object count text to the image\n",
        "text = f'Total Objects Detected: {object_count}'\n",
        "cv2.putText(labeled_image, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "# Display the annotated image with bounding boxes, labels, confidences, and object count\n",
        "display(labeled_image, 'Detected Objects with Bounding Boxes, Labels, and Count')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46b0f56e",
      "metadata": {},
      "source": [
        "##### 2.8 Printing Class, Confidences, and Coordinates\n",
        "\n",
        "Let's try to put our results into an easier to read format. Use a for loop and f-strings to print out different parts of the results.\n",
        "\n",
        "- [Results](https://docs.ultralytics.com/reference/engine/results/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955f7ae4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print details of detected objects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7435db5",
      "metadata": {},
      "source": [
        "#### 3. EXTRA Challenge: Try to replicate the process we did for images for videos.\n",
        "\n",
        "Let's try to put our results into an easier to read format. Use a for loop and f-strings to print out different parts of the results. You'll need to:\n",
        "1. Read frames from a video file.\n",
        "2. Apply the YOLO object detection model to each frame and annotate it.\n",
        "3. Save the processed frames to a new video file.\n",
        "\n",
        "- [OpenCV](https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9b79d5",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
